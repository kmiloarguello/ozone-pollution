# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16HeYOvInBETRENm9eIoLpeu2YC4ABXjb
"""

from google.colab import drive
drive.mount("/content/drive")

!apt-get install libgeos-3.5.0
!apt-get install libgeos-dev
!pip install https://github.com/matplotlib/basemap/archive/master.zip
!pip install http://sourceforge.net/projects/matplotlib/files/matplotlib-toolkits/

!pip install netcdf4
!pip install pyMCR
!pip install geopandas

"""# Libraries"""

#!/bin/env python
import sys
import glob
import os
import re
import numpy as np
import numpy.ma as ma
import pandas as pd
import matplotlib
#matplotlib.use('Agg')
import matplotlib.pyplot as plt
#plt.rcParams.update({'figure.max_open_warning': 0})
import matplotlib.colors as mcolors
from matplotlib.colors import ListedColormap
from scipy.interpolate import griddata
import torch
from mpl_toolkits.mplot3d import Axes3D
from PIL import Image
from skimage import measure, transform
#from skimage.segmentation import slic
#from skimage.segmentation import mark_boundaries
from skimage import io
from skimage import data, segmentation, color
from scipy.ndimage import label, generate_binary_structure
from scipy.spatial import distance
from scipy import ndimage
from shapely.geometry import Point, LineString, Polygon, LinearRing, MultiPoint
from descartes import PolygonPatch
import networkx as nx
import tarfile
import string
import calendar
import cv2
import random
from google.colab.patches import cv2_imshow
from mpl_toolkits.basemap import Basemap,cm
from mpl_toolkits.axes_grid1 import make_axes_locatable
import netCDF4
from geopandas import GeoSeries
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans
from sklearn import metrics
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
from scipy.signal import find_peaks
from sklearn.metrics.pairwise import euclidean_distances

DIR_DATA = '/content/drive/MyDrive/StageUParis/DATA/H2O/'
DIR_TRAIN = '/content/drive/MyDrive/StageUParis/DATA/LABELS/'
DIR_TEST = '/content/drive/MyDrive/StageUParis/Test/'

"""# Class **PollutionTracker**"""

class PollutionTracker():  
  image_type = "LT"
  year = 2008
  month = 5
  day = 1

  degree = 0.625
  pixel_size = 0.3125
  vmax = 35
  vmin = 10

  weight_gray_values = 1
  N_CLUSTERS = 2

  images = list()

  def __init__ (self,DIR_DATA=DIR_DATA, DIR_TRAIN=DIR_TRAIN):
    self.DIR_DATA = DIR_DATA
    self.DIR_TRAIN = DIR_TRAIN

  def __del__(self):
    print("Class finished")


  ############################################################################
  ####                      GETTERS AND SETTERS
  ############################################################################

  def set_DIR_DATA (self, DIR_DATA):
    self.DIR_DATA = DIR_DATA

  def get_DIR_DATA (self):
    return self.DIR_DATA

  def set_DIR_TRAIN (self, DIR_TRAIN):
    self.DIR_TRAIN = DIR_TRAIN
  
  def get_DIR_TRAIN (self):
    return self.DIR_TRAIN

  def set_DIR_TEST (self, DIR_TEST):
    self.DIR_TEST = DIR_TEST

  def get_DIR_TEST (self):
    return self.DIR_TEST

  def set_year(self,year):
    self.year = year

  def get_year(self):
    return self.year
  
  def set_month(self,month):
    self.month = month
  
  def get_month(self):
    return self.month

  def set_day(self,day):
    self.day = day

  def get_day(self):
    return self.day

  def set_image_type(self,image_type):
    self.image_type = image_type

  def get_image_type(self):
    return self.image_type

  def set_image_name(self,image_name):
    self.image_name = image_name

  def get_image_name(self):
    return self.image_name

  def set_pixel_size(self, degree, size):
    self.degree = degree
    self.pixel_size = size

  def set_region_area(self, max_area, min_area):
    self.max_area = max_area
    self.min_area = min_area

  def set_weight_gray_values(self, weight_gray_values):
    self.weight_gray_values = weight_gray_values

  def set_cluster_value (self, N_CLUSTERS):
    self.N_CLUSTERS = N_CLUSTERS

  def get_cluster_value(self):
    return self.N_CLUSTERS

  def set_vmin(self, vmin):
    self.vmin = vmin

  def get_vmin(self):
    return self.vmin
  
  def set_vmax(self, vmax):
    self.vmax = vmax

  def get_vmax(self):
    return self.vmax






  ############################################################################
  ####                        READ THE DATA
  ############################################################################

  def get_image_by_leves (self):
    #for index, layer in enumerate(np.arange(self.start, self.end, self.steps)):
    index = 0
    
    lat_g = np.arange(20.,50.,self.degree)
    lon_g = np.arange(100.,150.,self.degree)

    #initialization
    self.colgrid = np.zeros([lat_g.shape[0],lon_g.shape[0]], np.uint8)

    for year in range(self.year, self.year + 1):
      for month in range(self.month, self.month + 1):
        for day in range(self.day, self.day + 1):

          fname = self.DIR_DATA + 'IASIdaily_' + str(year) + '%02d'%month+'%02d'%day+'.nc'
          self.image_name = self.image_type + '-level-' + str(year) + '%02d'%month+'%02d'%day+'.png'

          print('reading info ...')

          if not(os.path.isfile(fname)):
            continue

          nc = netCDF4.Dataset(fname)
          flag = nc.variables['flag'][:]
          mask1 = (flag == 0) # Without clouds
          
          lat = nc.variables['lat'][mask1]
          lon = nc.variables['lon'][mask1]
          col = nc.variables[self.image_type][mask1]
          nc.close()

          mask2 = (np.isnan(col) == False) 

          # gridding the data
          for ilat in range(lat_g.shape[0]):
            for ilon in range(lon_g.shape[0]):
              # Grille régulier
              # 25 km
              # 0 25 degrée lattitude et longitude

              # Grille regulier of 0.125 degree
              maskgrid = (lat[:] >= (lat_g[ilat] - self.pixel_size)) & (lat[:] < (lat_g[ilat] + self.pixel_size)) & (lon[:] >= (lon_g[ilon] - self.pixel_size)) & (lon[:] < (lon_g[ilon] + self.pixel_size))
              
              # Defining invalid data
              mask = mask2 & maskgrid

              if len(col[mask]) != 0:
                median = np.mean(col[mask])
                #if median >= layer:
                self.colgrid[ilat,ilon] = median

          print('data readed correctly')

          # We mark the values at colgrid as invalid because they are maybe false positives or bad sampling
          self.colgrid1 = ma.masked_values(self.colgrid, 0.)

          self.v_x, self.v_y = np.meshgrid(lon_g, lat_g)
          gradx, grady = np.gradient(self.colgrid, edge_order=1)

          fig, (ax1) = plt.subplots(1, 1, figsize = (11,8))
          ax1.pcolormesh(self.v_x, self.v_y, self.colgrid, shading='nearest',cmap='gray', vmin=self.vmin, vmax=self.vmax)
          ax1.axis('off')
          fig.savefig(self.image_name, bbox_inches='tight', pad_inches=0)
          plt.close(fig)


          fig2, (ax2) = plt.subplots(1, 1, figsize = (11,8))
          ax2.pcolormesh(self.v_x, self.v_y, self.colgrid1, shading='nearest',cmap='jet', vmin=self.vmin, vmax=self.vmax)
          ax2.axis('off')
          fig2.savefig("color-" + self.image_name, bbox_inches='tight', pad_inches=0)
          plt.close(fig2)


  def get_image_datename(self):
    return ' IASI ' + self.image_type + " - " + str(self.day) +"/"+ str(self.month) +"/"+ str(self.year)



  def plot_original_image(self):

    #if self.image_type == 'LT':
    #  vmax = 35
    #  vmin = 3
    #else:
    #  vmax = 45
    #  vmin = 5

    fig, ax1 = plt.subplots(1,1)
    
    m=Basemap(llcrnrlon=100.,llcrnrlat=20.,urcrnrlon=150.,urcrnrlat=48.,resolution='i')
    m.drawcoastlines()
    m.drawmapboundary()
    m.drawmeridians(np.r_[100:151:10], labels=[0,0,0,1], color='grey',fontsize=8,linewidth=0)
    m.drawparallels(np.r_[20:48:5], labels=[1,0,0,0], color='grey',fontsize=8,linewidth=0)

    divider = make_axes_locatable(ax1)
    cax = divider.append_axes('right', size='1%', pad=0.05)
    cs = ax1.pcolormesh(self.v_x, self.v_y, self.colgrid1, shading='nearest',cmap='jet', vmin=self.vmin, vmax=self.vmax)
    ax1.set_title(self.get_image_datename())
    fig.colorbar(cs,cax=cax)
    


  ###############################################################
  ###             LOAD IMAGE INFORMATION
  ###############################################################

  def load_image_from_files (self, filename):
    img_bgr = io.imread(filename) 
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)

    return img_bgr, gray



  def process_set_images(self, image_gray, image_bgr):
    image, foreground, background = self.filter_image(image_gray)
    image,image_rbg,image_masked = self.filter_image_for_mser(image,foreground)
    regions_mser, boxes_mser = self.get_mser_regions(image_rbg)
    #self.plot_regions_mser_blue(image,regions_mser)

    kernel = np.ones((6,6), np.uint8)
    regx, regy, regs, polys, lines, values = self.set_mser_regions(image_masked, regions_mser)
    #self.plot_mser_final_regions(image_masked, regx, regy, values)
    #self.plot_polygons_hulls(image_masked,polys)

    image_projected, image_projected_mask = self.create_label_map(image, regions_mser)
    #self.plot_projected_image(image_projected, regions_mser,boxes_mser)

    labels_cc, num_cc = self.reconstruct_connected_component(image_projected_mask)
    centroids, grays_values, areas_partition, boxes_partition, ids_valid_regions = self.reconstruct_region_props(image_masked,labels_cc)
    #self.plot_regions_reconstructed(image_projected,centroids,areas_partition,grays_values,"du")

    X, weights = self.create_X(image_projected,centroids,grays_values,WEIGHT=5)
    #self.plot_X(X)
    #self.plot_weights(weights)

    #self.plot_test_best_cluster_number(X,weights,40,7)
    cluster_labels, cluster_centers = self.classify_regions(X,weights,7)
    #self.plot_clustered_regions_3d(X,5,cluster_labels,cluster_centers)







  ###############################################################
  ###             TRAITEMENT
  ###############################################################

  def filter_image (self, image):
    image = self.resize_image_percentage(image, 100)
    image = self.pretraitement_image(image,6,3)
    background, foreground = self.masking_interest_region(image)
    
    return image, foreground, background

  def resize_image_percentage (self, image, scale_percent = 100):
    ### SCALE
    width = int(image.shape[1] * scale_percent / 100)
    height = int(image.shape[0] * scale_percent / 100)
    dim = (width, height)
    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)

    return image

  def pretraitement_image(self, image, kernel_size = 9, iterations=3):
    ### MORPHO FILTERS
    kernel = np.ones((kernel_size,kernel_size),np.uint8)
    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel, iterations = iterations)

    return image

  ## REMOVING THE HOLES
  def masking_interest_region(self, image):
    # Take the holes (pixels value = 0) and set it as 255
    image = cv2.normalize(image, np.ones((image.shape[0], image.shape[0])), 0, self.vmax, cv2.NORM_MINMAX )
    image = np.where(image == 0, 255, image) 
    image = np.where(image != 255, 0, image) # This is the mask of the background
    image_holes_dilate = cv2.morphologyEx(image, cv2.MORPH_DILATE, np.ones((3,3),np.uint8), iterations = 3)
    image_holes_dilate_inv = cv2.bitwise_not(image_holes_dilate) # This is the mask of the foreground

    return image_holes_dilate, image_holes_dilate_inv

  def filter_image_for_mser(self, image, foreground):
    #kernel = np.ones((3,3),np.uint8)
    #foreground = cv2.dilate(foreground,kernel,iterations = 3)
    image = cv2.bitwise_and(image,image, mask=foreground)

    image_masked = ma.masked_values(image, 0.)
    image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    image_color = cv2.bitwise_and(image_color,image_color, mask=foreground)

    fig, ax = plt.subplots(1,1)
    ax.imshow(image_color)
  
    return image, image_color, image_masked
  
  ## REMOVING THE HOLES
  

  def get_mser_regions(self, image):
    """
    delta	          it compares (sizei−sizei−delta)/sizei−delta
    min_area	      prune the area which smaller than minArea
    max_area	      prune the area which bigger than maxArea
    max_variation	  prune the area have similar size to its children
    min_diversity	  for color image, trace back to cut off mser with diversity less than min_diversity
    max_evolution	  for color image, the evolution steps
    area_threshold	for color image, the area threshold to cause re-initialize
    min_margin	    for color image, ignore too small margin
    edge_blur_size	for color image, the aperture size for edge blur
    """

    mser = cv2.MSER_create( 1, # delta 
                        300, # min_area
                        34400, #max_area 
                        4., # max_variation 
                        .03, # min_diversity 
                        10000, # max_evolution 
                        1.04, # area_threshold 
                        0.003, # min_margin
                        5) # edge_blur_size

    # (1, 100, 20000, .25, 1., 1000, 1.001, 0.003, 5)
    regions, bboxes = mser.detectRegions(image)
    regions = sorted(regions, key=cv2.contourArea, reverse=True)

    bboxes = sorted(bboxes, key=self.sort_boxes_by_area, reverse=True)

    print("REGIONS found with MSER",len(regions))

    return regions, bboxes

  def sort_boxes_by_area(self, box):
    _, _, w, h = box
    area = w * h
    return area

  def plot_regions_mser_blue(self, image, regions):
    """
    image : image in gray level
    """
    img_mser = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

    for p in regions:
      for k in p:
        cv2.circle(img_mser, (k[0],k[1]), radius=0, color=(0, 0, 255), thickness=-1)
    fig, ax = plt.subplots(1,1)
    ax.imshow(img_mser)
    ax.set_title("REGIONS MSER " + self.get_image_datename())
    fig.show()




  ###############################################################
  ###             PLOTTING
  ###############################################################

  def set_mser_regions(self, image, regions):
    regsX = list()
    regsY = list()
    regs = list()
    regsPoly = list()
    regsLine = list()
    values_gray = list()

    for r in regions:
      region = list()
      hull = cv2.convexHull(r)

      for h in hull:
          region.append(h[0].tolist())

      region.append(region[0])
      poly = Polygon(region)
      line = LineString(region)
      value_pixel = self.get_region_value(image,poly)

      if np.isnan(value_pixel):
        print(value_pixel)
        break

      xs = [pnt[0] for pnt in r]
      ys = [pnt[1] for pnt in r]

      regsX.append(xs)
      regsY.append(ys)
      regs.append(r)
      regsPoly.append(poly)
      regsLine.append(line)
      values_gray.append(value_pixel)

    return regsX, regsY, regs, regsPoly, regsLine, values_gray

  def plot_polygons_hulls(self, image, polygons):
    fig, ax = plt.subplots(1,1)
    xx_range = [0, image.shape[1]]
    yy_range = [0, image.shape[0]]

    for poly in polygons:
      xxx,yyy = poly.exterior.xy

      ax.plot(xxx,yyy)
      ax.set_xlim(*xx_range)
      ax.set_ylim(*yy_range)
      ax.set_title("CONVEX HULLS MSER " + self.get_image_datename())
      ax.invert_yaxis()

    fig.show()

  def plot_mser_final_regions (self, image, regsX, regsY, values):
    x_range = [100, 150, 10]
    y_range = [20, 48, 5]

    rgsX2 = list()
    rgsY2 = list()

    for reg in regsX:
      line = list()
      for i in reg:
        line.append((i / (image.shape[1] / 50)) + 100)
      rgsX2.append(line)

    for reg in regsY:
      line = list()
      for i in reg:
        line.append(((image.shape[0] - i) / (image.shape[0] / 28)) + 20)
      rgsY2.append(line)

    fig, ax = plt.subplots(1,1)
    m=Basemap(llcrnrlon=100.,llcrnrlat=20.,urcrnrlon=150.,urcrnrlat=48.,resolution='i')
    m.drawcoastlines()
    m.drawmapboundary()
    m.drawmeridians(np.r_[100:151:10], labels=[0,0,0,1], color='grey',fontsize=8,linewidth=0)
    m.drawparallels(np.r_[20:48:5], labels=[1,0,0,0], color='grey',fontsize=8,linewidth=0)

    max_color_value = self.vmax
    
    colors = sns.color_palette("YlOrBr", self.vmax + 1)
    cmap = matplotlib.colors.ListedColormap(colors)
    norm = matplotlib.colors.BoundaryNorm(np.arange(self.vmin, self.vmax + 1) - 0.5, cmap.N)

    for i,val in enumerate(values):
      ax.scatter(rgsX2[i], rgsY2[i], marker='.', color=cmap(norm(int(val))) )
      ax.set_xlim(*x_range)
      ax.set_ylim(*y_range)
      ax.set_title('REGIONS ' + str(len(values)) + self.get_image_datename())

    sm = matplotlib.cm.ScalarMappable(cmap=cmap, norm=norm)
    cbar_ax = fig.add_axes([0.09, 0.06, 0.84, 0.02])
    cb = fig.colorbar(sm,cax=cbar_ax,orientation='horizontal')
    if self.image_type == "UT":
      cb.set_ticklabels(np.arange(self.vmin,self.vmax + 1,int(self.vmax / 10 )))
    else:
      cb.set_ticklabels(np.arange(self.vmin,self.vmax + 1, int(self.vmax / 9) )) # 9 is the number of values plotted in the colorbar i.e [10--13--16--...--35]

    cb.set_label('DU')

  def get_region_value(self, image, polygon, isABox=False):
    """
    This function returns the mean pixel value from a given polygon
    """
    image = cv2.normalize(image, np.ones((image.shape[0], image.shape[0])) , self.vmin, self.vmax, cv2.NORM_MINMAX )

    if isABox:
      minx, miny, maxx, maxy = polygon
    else:
      minx, miny, maxx, maxy = polygon.bounds #Boite englobante

    pixel_steps_x = image.shape[1] * self.degree / self.colgrid.shape[1]
    pixel_steps_y = image.shape[0] * self.degree / self.colgrid.shape[0]

    longs = np.arange(minx, maxx, pixel_steps_x)
    lats = np.arange(miny, maxy, pixel_steps_y)

    set_of_coordinates = list()
    for lon in longs:
      for lat in lats:
        if np.isnan(lat):
          print("lat is nan")
        if np.isnan(lon):
          print("lon is nan")

        if image[int(lat), int(lon)] > 0:
          set_of_coordinates.append(image[int(lat), int(lon)])

    value_pixel = np.mean(set_of_coordinates)

    if np.isnan(value_pixel):
      value_pixel = 1.
    
    return value_pixel

  def create_label_map(self,image, regions):
    # Creation of Carte de labels
    projected = np.zeros(image.shape, np.uint16)
    connected_components = list()

    for i,r in enumerate(regions):
      counter = (i + 1)
      
      counter_has_summed = False
      cc_has_summed = False

      for k in r:
        if projected[k[1]][k[0]] != 0:

          ## search intersection
          if counter_has_summed is False:
            counter = counter + 1
            connected_components.append(counter)
            counter_has_summed = True

          cv2.circle(projected, (k[0],k[1]), radius=1, color=(counter), thickness=-1, lineType=cv2.FILLED)
        else:
          if cc_has_summed is False:
            connected_components.append(counter)
            cc_has_summed = True
          
          cv2.circle(projected, (k[0],k[1]), radius=1, color=(counter), thickness=-1, lineType=cv2.FILLED)
        
    kernel = np.ones((3,3), np.uint8)
    projected = cv2.morphologyEx(projected, cv2.MORPH_CLOSE, kernel, iterations = 2)

    projected_masked = ma.masked_values(projected, 0.)

    return projected, projected_masked

  def plot_projected_image(self, image_projected, regions, boxes):
    # font
    font = cv2.FONT_HERSHEY_SIMPLEX
    # Blue color in BGR
    color = (255, 0, 0)
    # Line thickness of 2 px
    thickness = 1

    image_projected_color = cv2.cvtColor(image_projected, cv2.COLOR_GRAY2BGR)

    for box in boxes:
      x, y, w, h = box
      cv2.rectangle(image_projected_color, (x, y), (x + w, y + h), (0, 0, 255), 2)

    # Using cv2.putText() method
    for i,r in enumerate(regions):
      cv2.putText(image_projected_color, str(i+1), (r[0][0] + 10, r[0][1]), font, 1, color, thickness, cv2.LINE_AA)

    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(21,15))
    ax1.imshow(image_projected, cmap="gray")
    ax1.set_title("Label map gray scale")
    ax2.imshow(image_projected_color)
    ax2.set_title("Label map with container box")
    plt.title("Label map " + self.get_image_datename())
    fig.show()

  def reconstruct_connected_component(self, image_projected):
    labels, num = measure.label(image_projected, return_num=True, background=0.)
    print("Total connected components", num)
    return labels, num

  def reconstruct_region_props(self, image_masked, labels_cc, min_width=10, min_height=10):
    # return centroids
    rescale=1.0
    centroids = list()
    areas_partition = list()
    boxes_partition = list()
    grays_values = list()
    ids_valid_regions = list()

    for i,region in enumerate(measure.regionprops(label_image=labels_cc)):
      x_min = region.bbox[1]
      x_max = region.bbox[3]
      y_min = region.bbox[0]
      y_max = region.bbox[2]
      # TODO: CORREGIR EL PROBLEMA CON LAS CLUSTERS Y LAS REGIONES QUE SE PIERDEN
      #if (x_max - x_min) > min_width and (y_max - y_min) > min_height:
      boxes_partition.append(np.array([x_min,y_min,x_max,y_max]))
      cx, cy = map(lambda p: int(p*rescale), (region.centroid[0], region.centroid[1]))
      centroids.append((cx, cy))
      areas_partition.append(region.area)
      grays_values.append(self.get_region_value(image_masked,np.array([x_min,y_min,x_max,y_max]),True)) # Gray values for the regions partitions
      ids_valid_regions.append(i) # List to compare with CC. The idea is to rebuild the region as image, to do that we need the region id

    print("Regions reconstructed",len(centroids))

    return centroids, grays_values, areas_partition, boxes_partition, ids_valid_regions

  def plot_regions_reconstructed(self, image_projected, centroids, areas_partition, grays_values, text_to_plot="id"):
    # font
    font = cv2.FONT_HERSHEY_SIMPLEX
    # Line thickness of 2 px
    thickness = 1
    
    image_projected = cv2.cvtColor(image_projected, cv2.COLOR_GRAY2BGR)

    for i in range(len(centroids)):
        color = (random.randint(0,256), random.randint(0,256), random.randint(0,256))
        text = None

        if text_to_plot == "id":
          text = str(i+1)
        elif text_to_plot == "area":
          text = str(int(areas_partition[i]))
        elif text_to_plot == "du":
          text = str(int(grays_values[i]))
        else:
          text = str(i+1)

        # ID: str(i+1)
        # Area: str(areas_partition[i])
        # DU: str(int(imageLT.get_region_value(t_i,boxes_partition[i],True)))

        cv2.putText(image_projected, text, (int(centroids[i][1]), int(centroids[i][0])), font, .5, color, thickness, cv2.LINE_AA)
        cv2.circle(image_projected, (int(centroids[i][1]), int(centroids[i][0])), 3, color, -1)

    fig, ax = plt.subplots(1,1, figsize=(15,10))
    ax.imshow(image_projected)
    ax.set_title(text_to_plot + self.get_image_datename())
    fig.show()

  ## CLUSTERING




  def sigmoid(self,X):
    return np.exp(X)
    #return 1/(1+np.exp(X))

  def softmax(self,X):
    expo = np.exp(X)
    expo_sum = np.sum(np.exp(X))
    return expo/expo_sum


  def create_X(self, image_projected, centroids, grays_values, WEIGHT=5):
    x_norm = list() # array with centre de gravite x, y and gray value [(x,y,z)]
    weights_list = list()
    grays = grays_values.copy()

    ## CREATE ARRAY BEFORE NORMALIZATION
    for gray in grays:
      tmp_w = WEIGHT
      #if WEIGHT > 1:
      #  tmp_w = WEIGHT * np.exp(gray)
      weights_list.append(tmp_w * gray)

    #g_v = np.asarray(grays_values)
    #Example with mmatrix defined above
    #weights_list = self.sigmoid(g_v)

    gray_values_norm = (grays - min(grays)) / (max(grays) - min(grays))

    for i,centroid in enumerate(centroids[:]):
      x = centroid[0] / image_projected.shape[0]
      y = centroid[1] / image_projected.shape[1]
      z = gray_values_norm[i]
      x_norm.append(np.array([x,y,z]))

    X = np.asarray(x_norm)
    # weights = np.asarray(weights_list) # weights_list.copy() 
    
    return X, weights_list

  def plot_X(self,X):
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')

    for i in range(len(X)):
      ax.scatter(X[i,0],X[i,1],X[i,2])

    plt.title("X" + self.get_image_datename()) 
    ax.set_xlabel('Centre de gravité X')
    ax.set_ylabel('Centre de gravité Y')
    ax.set_zlabel('DU - normalized [0-1]')
    fig.show()

  def plot_weights(self, weigths):
    fig, ax = plt.subplots(1,1)
    ax.plot(weigths)
    ax.set_title("Weigths" + self.get_image_datename())
    ax.set_xlabel("Number of Regions")
    ax.set_ylabel("Weight")
    fig.show()

  def plot_test_best_cluster_number(self, X, weights, N_ITERATIONS= 40, N_CLUSTERS = 7):
    # TESTING KMEANS
    wcss = list()
    # int((len(centers) / 5))
    print("finding best cluster...")
    for i in range(1,N_ITERATIONS):
      #print("kmeans for cluster #",i)
      kmeanstest = KMeans(n_clusters=i, random_state=0, max_iter=500).fit(X, sample_weight=np.asarray(weights))
      wcss.append(kmeanstest.inertia_)

    fig0, ax = plt.subplots(1,1)
    ax.scatter(N_CLUSTERS,wcss[N_CLUSTERS], c='red', label="Selected cluster")
    ax.plot( np.arange(len(wcss)) , wcss)
    ax.set_title("Optimal number of clusters")
    ax.set_xlabel("Number of clusters (k)")
    ax.set_ylabel("Inertia")
    fig0.legend()

  def classify_regions(self,X,weights,N_CLUSTERS=7):
    print("clustering...")

    clustering = KMeans(n_clusters=N_CLUSTERS,random_state=0, init='k-means++')
    cluster_labels = clustering.fit_predict(X, sample_weight=np.asarray(weights))
    cluster_centers = clustering.cluster_centers_

    print("Cluster finished.")

    return cluster_labels, cluster_centers, clustering

  def plot_clustered_regions_3d(self,X,WEIGHT,cluster_labels, cluster_centers):
    # visualizing the clusters
    fig = plt.figure(figsize=(11,8))
    ax = fig.add_subplot(111, projection='3d')

    #X_gray_norm = X[:,2]
    #X_gray = cv2.normalize(X_gray_norm, None, alpha=self.vmin, beta=self.vmax, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)

    for i in range(max(cluster_labels) + 1):
      ax.scatter(X[cluster_labels==i,0],X[cluster_labels==i,1],X[cluster_labels==i,2], label="cluster " + str(i+1))

    #c_center_norm = cluster_centers[:,2]
    #c_center = cv2.normalize(c_center_norm, None, alpha=self.vmin, beta=self.vmax, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)
    ax.scatter(cluster_centers[:,0],cluster_centers[:,1],cluster_centers[:,2],s=200,c="black",label="centroid "+str(i))

    ax.set_title("CLUSTERING W: " + str(WEIGHT) + self.get_image_datename()) 
    ax.set_xlabel('Centre de gravité X')
    ax.set_ylabel('Centre de gravité Y')
    ax.set_zlabel('Gray level normalized')
    fig.legend()
    ax.view_init(30, 30)
    plt.draw()
    plt.pause(.001)
    fig.show()
    plt.show()

  def plot_clustered_regions_2d(self,X,WEIGHT,cluster_labels, cluster_centers):
    for i in range(len(cluster_centers) - 1):
      distances = list()
      for j in range(len(cluster_centers)):
        xx = [cluster_centers[i][0], cluster_centers[j][0]]
        m_x = (xx[1] + xx[0]) / 2
        yy = [cluster_centers[i][1], cluster_centers[j][1]]
        m_y = (yy[1] + yy[0]) / 2

        d_1 = distance.euclidean(xx, yy)
        distances.append(d_1)

      #np.argmax(distances)
      #print(distances)
    fig, ax = plt.subplots(1,1)

    dists = euclidean_distances(cluster_centers)

    for i, dist in enumerate(dists):
      max_dist = dist[np.argmax(dist)] * 20000
      ax.scatter( cluster_centers[i,1],cluster_centers[i,0] , s=int(max_dist) ,  facecolors='none', edgecolors='blue' ) 

    #print(euclidean_distances(cluster_centers[0], cluster_centers[1:]))


    for i in range(max(cluster_labels) + 1 ):
      ax.scatter(X[cluster_labels==i,1],X[cluster_labels==i,0],label="cluster " + str(i+1))
      

    ax.scatter(cluster_centers[:,1],cluster_centers[:,0],s=200,c="black",label="centroid")
    ax.set_title("CLUSTERING W: " + str(WEIGHT) + self.get_image_datename()) 
    ax.set_xlabel("Centre de gravité X")
    ax.set_ylabel("Centre de gravité Y")
    ax.invert_yaxis()
    fig.legend()
    fig.show()

  def get_highest_cluster(self, cluster_centers):
    # TO TAKE ONLY THE HIHGEST REGION (TEST)

    cluster_highest_region = list()

    for center in cluster_centers:
      cluster_highest_region.append(center[2])

    index_highest = np.argmax(cluster_highest_region)
    highest_cluster = cluster_centers[index_highest]

    return highest_cluster, index_highest


  def get_image_cluster(self, labels_cc, cluster_labels):
    image_cluster = np.zeros(labels_cc.shape, np.uint8)
    cluster_labels1 = cluster_labels.copy()
    cluster_labels1 += 1

    for i,lbl in enumerate(cluster_labels[:]):
      image_cluster = np.where(labels_cc == (i+1), lbl + 1, image_cluster)

    fig,axx = plt.subplots(1,1)
    axx.imshow(image_cluster, cmap="jet")

    return image_cluster

  def plot_image_cluster(self, labels_cc, cluster_labels, index_highest):
    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(11,8))
    tmp = np.zeros(labels_cc.shape, np.uint8)
    tmp1 = tmp.copy()

    cluster_labels1 = cluster_labels.copy()
    cluster_labels1 += 1

    for i,lbl in enumerate(cluster_labels[:]):
      tmp = np.where(labels_cc == (i+1), lbl + 1, tmp)

    tmp1 = np.where(tmp == (index_highest + 1),1,0)

    ax1.imshow(tmp, "jet")
    ax2.imshow(tmp1, "gray")
    fig.show()


  def plot_silhouette_coefficient(self, X, weights):
    # visualizing Silhouette coefficient
    for n_clusters in range(2,15):
      # Create a subplot with 1 row and 2 columns
      fig, (ax1, ax2) = plt.subplots(1, 2)
      fig.set_size_inches(18, 7)
      # The 1st subplot is the silhouette plot
      # The silhouette coefficient can range from -1, 1 but in this example all
      # lie within [-0.1, 1]
      ax1.set_xlim([-0.1, 1])
      # The (n_clusters+1)*10 is for inserting blank space between silhouette
      # plots of individual clusters, to demarcate them clearly.
      ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])
      # Initialize the clusterer with n_clusters value and a random generator
      # seed of 10 for reproducibility.
      clusterer = KMeans(n_clusters=n_clusters, random_state=10)
      cluster_labels = clusterer.fit_predict(X, sample_weight=weights)
      # The silhouette_score gives the average value for all the samples.
      # This gives a perspective into the density and separation of the formed
      # clusters
      silhouette_avg = metrics.silhouette_score(X, cluster_labels)
      print("For n_clusters =", n_clusters, "The average silhouette_score is :", silhouette_avg)
      # Compute the silhouette scores for each sample
      sample_silhouette_values = metrics.silhouette_samples(X, cluster_labels)
      y_lower = 10
      
      for i in range(n_clusters):
        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]
        ith_cluster_silhouette_values.sort()
        
        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i
        #color = cm.nipy_spectral(float(i) / n_clusters) 
        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,alpha=0.7)
        
        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
        
        y_lower = y_upper + 10 # 10 for the 0 samples
        ax1.set_title("The silhouette plot for the various clusters.")
        ax1.set_xlabel("The silhouette coefficient values")
        ax1.set_ylabel("Cluster label")
        
        ax1.axvline(x=silhouette_avg, color="red", linestyle="--")
        ax1.set_yticks([]) # Clear the yaxis labels / ticks
        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])
        
        #colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)
        ax2.scatter(X[:, 0], X[:, 1], marker=".", s=30, lw=0, alpha=0.7, edgecolor="k")
        
        centers = clusterer.cluster_centers_
        ax2.scatter(centers[:, 0], centers[:, 1], marker="o",c="white", alpha=1, s=200, edgecolor="k")
        
        for i, c in enumerate(centers):
          ax2.scatter(c[0], c[1], marker="$%d$" % i, alpha=1,s=50, edgecolor="k")
          ax2.set_title("The visualization of the clustered data.")
          ax2.set_xlabel("Feature space for the 1st feature")
          ax2.set_ylabel("Feature space for the 2nd feature")
          plt.suptitle(("Silhouette analysis for KMeans clustering on sample data with n_clusters = %d" % n_clusters), fontsize=14, fontweight="bold")
      plt.show()

  
  ###############################################################
  ###             REMOVE TEMP FILES
  ###############################################################

  def remove_temporal_files(self):
    try:
      os.remove(self.image_name)
      #Raising your own errors
      raise ErrorType("Deleting")
    except ErrorType as e:
      print("Error deleting the file -> ", self.image_name)

def get_clusters_days(year,month,day,image_type,vmax):
  WEIGHT = 2
  N_CLUSTERS = 10

  pollution = PollutionTracker()
  pollution.set_year(year)
  pollution.set_month(month)
  pollution.set_day(day)
  pollution.set_image_type(image_type)
  pollution.set_vmin(10)
  pollution.set_vmax(vmax)
  pollution.set_image_name("levels")
  pollution.set_weight_gray_values(1)
  pollution.set_cluster_value(30)
  pollution.set_pixel_size(0.25,.125)
  pollution.get_image_by_leves()
  image_bgr , image_gray = pollution.load_image_from_files(pollution.get_image_name())
  image, foreground, background = pollution.filter_image(image_gray)
  image,image_rbg,image_masked = pollution.filter_image_for_mser(image,foreground)
  regions_mser, boxes_mser = pollution.get_mser_regions(image_rbg)
  image_projected, image_projected_mask = pollution.create_label_map(image, regions_mser)
  labels_cc, num_cc = pollution.reconstruct_connected_component(image_projected_mask)
  centroids, grays_values, areas_partition, boxes_partition, ids_valid_regions = pollution.reconstruct_region_props(image_masked,labels_cc,10,10)
  X, weights = pollution.create_X(image_projected,centroids,grays_values,WEIGHT)
  cluster_labels, cluster_centers, model = pollution.classify_regions(X,weights,N_CLUSTERS)
  #pollution.plot_test_best_cluster_number(X,weights,40,10)
  image_cluster = pollution.get_image_cluster(labels_cc,cluster_labels)
  #pollution.plot_original_image()
  #regx, regy, regs, polys, lines, values = pollution.set_mser_regions(image_masked, regions_mser)
  #pollution.plot_mser_final_regions(image_masked, regx, regy, values)
  #pollution.plot_projected_image(image_projected,regions_mser,boxes_mser)
  #pollution.plot_regions_reconstructed(image_projected, centroids, areas_partition, grays_values,'id')
  #pollution.plot_clustered_regions_2d(X,WEIGHT, cluster_labels, cluster_centers)
  #pollution.plot_clustered_regions_3d(X,WEIGHT,cluster_labels,cluster_centers)

  return X,cluster_labels,cluster_centers,weights,image_cluster,grays_values,centroids

all_input_lt = list()
all_input_ut = list()

all_labels_lt = list()
all_labels_ut = list()

all_centers_lt = list()
all_centers_ut = list()

all_weights_lt = list()
all_weights_ut = list()

all_images_cluster_lt = list()
all_images_cluster_ut = list()

all_grays_vals = list()
all_centroids_vals = list()

for i in range(1,8):
  print(i)
  X_lt, labels_lt, centers_lt , weights_lt, image_cluster_lt, gray_val, centroid_val = get_clusters_days(2008,5,i,"LT",35)
  #X_ut, labels_ut, centers_ut , weights_ut, image_cluster_ut = get_clusters_days(2008,5,i,"UT",45)
  all_input_lt.append(X_lt)
  #all_input_ut.append(X_ut)
  all_labels_lt.append(labels_lt)
  #all_labels_ut.append(labels_ut)
  all_centers_lt.append(centers_lt)
  #all_centers_ut.append(centers_ut)
  all_weights_lt.append(weights_lt)
  #all_weights_ut.append(weights_ut)
  all_images_cluster_lt.append(image_cluster_lt)
  #all_images_cluster_ut.append(image_cluster_ut)
  all_grays_vals.append(gray_val)
  all_centroids_vals.append(centroid_val)

test_c_ut = all_centers_ut.copy()

export_centers_ut_x = ['center_x']
export_centers_ut_y = ['center_y']
export_centers_ut_z = ['center_z']
export_day_c = ['day']

for i in range(len(test_c_ut)):
  for c in test_c_ut[i][:,0]:
    export_centers_ut_x.append(c)
    # append the day also
    export_day_c.append((i+1))
  for c in test_c_ut[i][:,1]:
    export_centers_ut_y.append(c)
  for c in test_c_ut[i][:,2]:
    export_centers_ut_z.append(c)

np.savetxt('export_centers_ut.csv', [p for p in zip(export_centers_ut_x, export_centers_ut_y,export_centers_ut_z,export_day_c)], delimiter=',', fmt='%s')

test_c_lt = all_centers_lt.copy()

export_centers_lt_x = ['center_x']
export_centers_lt_y = ['center_y']
export_centers_lt_z = ['center_z']
export_day_c = ['day']

for i in range(len(test_c_lt)):
  for c in test_c_lt[i][:,0]:
    export_centers_lt_x.append(c)
    # append the day also
    export_day_c.append((i+1))
  for c in test_c_lt[i][:,1]:
    export_centers_lt_y.append(c)
  for c in test_c_lt[i][:,2]:
    export_centers_lt_z.append(c)

np.savetxt('export_centers_lt.csv', [p for p in zip(export_centers_lt_x, export_centers_lt_y,export_centers_lt_z,export_day_c)], delimiter=',', fmt='%s')

test_i_ut = all_input_ut.copy()
test_l_ut = all_labels_ut.copy()
test_w_ut = all_weights_ut.copy()

export_input_ut_x = ['X_m']
export_input_ut_y = ['Y_m']
export_input_ut_z = ['Z_m']
export_label_ut = ['label']
export_weight_ut = ['w']
export_day_ut = ['day']

for i in range(len(test_i_ut)):
  
  for c in test_i_ut[i][:,0]:
    export_input_ut_x.append(c)
    # append the day also
    export_day_ut.append((i+1))
  
  for c in test_i_ut[i][:,1]:
    export_input_ut_y.append(c)
  
  for c in test_i_ut[i][:,2]:
    export_input_ut_z.append(c)

  for l in test_l_ut[i]:
    export_label_ut.append(l)

  for w in test_w_ut[i]:
    export_weight_ut.append(w)

np.savetxt('export_ut.csv', [p for p in zip(export_input_ut_x, export_input_ut_y,export_input_ut_z,export_label_ut,export_weight_ut,export_day_ut)], delimiter=',', fmt='%s')

test_i_lt = all_input_lt.copy()
test_l_lt = all_labels_lt.copy()
test_w_lt = all_weights_lt.copy()

export_input_lt_x = ['X_m']
export_input_lt_y = ['Y_m']
export_input_lt_z = ['Z_m']
export_label_lt = ['label']
export_weight_lt = ['w']
export_day_lt = ['day']

for i in range(len(test_i_lt)):
  
  for c in test_i_lt[i][:,0]:
    export_input_lt_x.append(c)
    # append the day also
    export_day_lt.append((i+1))
  
  for c in test_i_lt[i][:,1]:
    export_input_lt_y.append(c)
  
  for c in test_i_lt[i][:,2]:
    export_input_lt_z.append(c)

  for l in test_l_lt[i]:
    export_label_lt.append(l)

  for w in test_w_lt[i]:
    export_weight_lt.append(w)

np.savetxt('export_lt.csv', [p for p in zip(export_input_lt_x, export_input_lt_y,export_input_lt_z,export_label_lt,export_weight_lt,export_day_lt)], delimiter=',', fmt='%s')

print("hi")







#from yellowbrick.cluster import InterclusterDistance

# Generate synthetic dataset with 12 random clusters
#X, y = make_blobs(n_samples=1000, n_features=12, centers=12, random_state=42)

# Instantiate the clustering model and visualizer
#model = KMeans(6)
#visualizer = InterclusterDistance(model)
#visualizer.fit(X)        # Fit the data to the visualizer
#visualizer.show()        # Finalize and render the figure

WEIGHT = 2
N_CLUSTERS = 10

pollution1 = PollutionTracker()
pollution1.set_year(2008)
pollution1.set_month(5)
pollution1.set_day(6)
pollution1.set_image_type("UT")
pollution1.set_vmin(10)
pollution1.set_vmax(45)
pollution1.set_image_name("levels")
pollution1.set_weight_gray_values(1)
pollution1.set_cluster_value(30)
pollution1.set_pixel_size(0.25,.125)
pollution1.get_image_by_leves()
image_bgr , image_gray = pollution1.load_image_from_files(pollution1.get_image_name())
image, foreground, background = pollution1.filter_image(image_gray)
image,image_rbg,image_masked = pollution1.filter_image_for_mser(image,foreground)
regions_mser, boxes_mser = pollution1.get_mser_regions(image_rbg)
image_projected, image_projected_mask = pollution1.create_label_map(image, regions_mser)
labels_cc, num_cc = pollution1.reconstruct_connected_component(image_projected_mask)
centroids, grays_values, areas_partition, boxes_partition, ids_valid_regions = pollution1.reconstruct_region_props(image_masked,labels_cc,10,10)
X, weights = pollution1.create_X(image_projected,centroids,grays_values,WEIGHT)
cluster_labels, cluster_centers, model = pollution1.classify_regions(X,weights,N_CLUSTERS)
#pollution.plot_test_best_cluster_number(X,weights,40,10)
image_cluster = pollution1.get_image_cluster(labels_cc,cluster_labels)
pollution1.plot_projected_image(image_projected,regions_mser,boxes_mser)
pollution1.plot_clustered_regions_3d(X, WEIGHT, cluster_labels, cluster_centers)

print(len(centroids), len(cluster_labels))

for i in range(1,len(cluster_centers) + 1):
  print("i", i)
  f, ax = plt.subplots(1,1)
  im_orig = np.zeros(image_cluster.shape, np.uint8)
  im_orig = np.where(image_cluster == i,1, im_orig)
  ax.imshow(im_orig)
  ax.set_title("i:" + str(i))

plt.imshow(image)

pollution1.vmax

"""
hola
x_range = [100, 150, 10]
y_range = [20, 48, 5]

rgsX2 = list()
rgsY2 = list()

for reg in regsX:
line = list()
for i in reg:
line.append((i / (image.shape[1] / 50)) + 100)
rgsX2.append(line)

for reg in regsY:
line = list()
for i in reg:
line.append(((image.shape[0] - i) / (image.shape[0] / 28)) + 20)
rgsY2.append(line)
"""
def get_region_value2(image, polygon):
    """
    This function returns the mean pixel value from a given polygon
    """
    #image = cv2.normalize(image, np.ones((image.shape[0], image.shape[0])) , pollution1.vmin, pollution1.vmax, cv2.NORM_MINMAX )
    #image = cv2.bitwise_and(image,image, mask=foreground)

    image = cv2.normalize(image, np.ones((image.shape[0], image.shape[0])) , pollution1.vmin, pollution1.vmax, cv2.NORM_MINMAX )
    image = cv2.bitwise_and(image,image, mask=foreground)

    #minx, miny, maxx, maxy = polygon
    #xx,yy,ww,hh = polygon

    #maxx = ((minx + maxx) / (image.shape[1] / 50)) + 100
    #minx = (minx / (image.shape[1] / 50)) + 100
    
    #miny = ((image.shape[0] - miny) / (image.shape[0] / 28)) + 20
    #maxy = ((image.shape[0] - maxy) / (image.shape[0] / 28)) + 20

    #pixel_steps_x = image.shape[1] * pollution1.degree / pollution1.colgrid.shape[1]
    #pixel_steps_y = image.shape[0] * pollution1.degree / pollution1.colgrid.shape[0]
    x,y,w,h = polygon
    longs = np.arange(x, (x+w), 1)
    lats = np.arange(y, (y+h), 1) # inverted min and max due errors in mapping

    set_of_coordinates = list()
    for lon in longs:
      for lat in lats:
        if np.isnan(lat):
          print("lat is nan")
        if np.isnan(lon):
          print("lon is nan")

        if image[int(lat), int(lon)] > 0:
          set_of_coordinates.append(image[int(lat), int(lon)])

    #print(set_of_coordinates)

    value_pixel = np.mean(set_of_coordinates)

    if np.isnan(value_pixel):
      value_pixel = 1.
    
    return value_pixel

plt.scatter([508],[156])
plt.imshow(image_masked)
print(image_masked[156,508])



image222 = cv2.normalize(image_masked, np.ones((image_masked.shape[0], image_masked.shape[0])) , pollution1.vmin, pollution1.vmax, cv2.NORM_MINMAX )
image222 = cv2.bitwise_and(image222,image222, mask=foreground)

plt.scatter([508],[156])
plt.scatter([550],[50])
plt.imshow(image222)
print(image222[156,508])
print(image222[50,550])

image222 = cv2.bitwise_and(image222,image222, mask=foreground)
plt.imshow(image222)

print(image222[156,508])
print(image222[50,550])



regg = 9
seuil = 15

im_orig = np.zeros(image_cluster.shape, np.uint8)
im_orig = np.where(image_cluster == regg,1, im_orig)
contours_orig, _ = cv2.findContours(im_orig, 1, 2)




for i,cnt in enumerate(contours_orig):
  box = cv2.boundingRect(cnt)
  x,y,w,h = box
  
  if ( w*h ) > 10000:
    g = get_region_value2(image_masked,box)
    print(g)
    #cv2.rectangle(im_orig,(x,y),(x+w,y+h),(255,255,255),2)
    im_orig = np.where(image_cluster == regg,g, im_orig)

im_orig = np.where(im_orig < seuil, 0, im_orig)
plt.imshow(im_orig, cmap="gray")

dani = 0
for x in im_orig:
  for y in x:
    if y != 0:
      if dani < 3:
        print(y)
        dani += 1

len(cluster_centers)



def get_image_from_seuil (seuil = 0):
  im_acum = np.zeros(image_cluster.shape, np.uint8)

  for cl in range(1,11):
    im_orig = np.zeros(image_cluster.shape, np.uint8)
    im_orig = np.where(image_cluster == cl,1, im_orig)
    contours_orig, _ = cv2.findContours(im_orig, 1, 2)

    for i,cnt in enumerate(contours_orig):
      box = cv2.boundingRect(cnt)
      x,y,w,h = box
      
      if ( w*h ) > 1000:
        g = get_region_value2(image_masked,box)
        #print(g)
        im_acum = np.where(image_cluster == cl, g, im_acum)
        #cv2.rectangle(im_orig,(x,y),(x+w,y+h),(255,255,255),2)
        im_orig = np.where(image_cluster == cl,g, im_orig)

    im_acum = np.where(im_acum < seuil, 0, im_acum)

  return im_acum

im_acum = np.zeros(image_cluster.shape, np.uint8)

for cl in range(1,11):
  seuil = 27

  im_orig = np.zeros(image_cluster.shape, np.uint8)
  im_orig = np.where(image_cluster == cl,1, im_orig)
  contours_orig, _ = cv2.findContours(im_orig, 1, 2)

  for i,cnt in enumerate(contours_orig):
    box = cv2.boundingRect(cnt)
    x,y,w,h = box
    
    if ( w*h ) > 1000:
      g = get_region_value2(image_masked,box)
      #print(g)
      im_acum = np.where(image_cluster == cl, g, im_acum)
      #cv2.rectangle(im_orig,(x,y),(x+w,y+h),(255,255,255),2)
      im_orig = np.where(image_cluster == cl,g, im_orig)

  im_acum = np.where(im_acum < seuil, 0, im_acum)
  #ll, nn = measure.label(im_acum, return_num=True, background=0.)
  
  plt.imshow(im_acum, cmap="jet")
  plt.title("Cluster " + str(cl) + " - Threshold: " + str(seuil) + " DU")

directories = os.listdir( DIR_TRAIN )

# This would print all the files and directories
for file in directories:
  only_png_files = re.search(".jpg", file)
  if only_png_files is not None:
    only_same_day = re.search(str(2008)+"%02d"%5+"%02d"%6, file)
    if only_same_day is not None:
      only_image_type = re.search("UT", file)
      if only_image_type is not None:
        img = io.imread(DIR_TRAIN + file)
        #img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
        img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        #img_gray = ma.masked_values(img_gray, 255.)
        img_gray = cv2.GaussianBlur(img_gray,(5,5),cv2.BORDER_DEFAULT)

        all_true_positives_c = list()
        all_false_positives_c = list()
        all_false_negatives_c = list()

        for t in range(45):
          print("\n")
          im_orig = get_image_from_seuil(t)
          im_bin = img_gray.copy()

          total_pixels_blancs_ref = len(im_bin[im_bin != 0])
          total_pixels_blancs_test = len(im_orig[im_orig != 0])

          if total_pixels_blancs_test == 0:
            break

          im_orig = np.where(im_orig != 0, 1, im_orig)
          c_m_temp = confusion_matrix(im_bin.flatten(), im_orig.flatten())
          true_positives = c_m_temp[1][1]
          false_positives = c_m_temp[0][1]
          false_negatives = c_m_temp[1][0]
          true_negatives = c_m_temp[0][0]

          all_true_positives_c.append(true_positives * 100 / total_pixels_blancs_test)
          all_false_positives_c.append(false_positives * 100 / total_pixels_blancs_test)
          all_false_negatives_c.append(false_negatives * 100 / total_pixels_blancs_ref)

          error = np.sum(np.abs(im_orig - im_bin))
          print(error)

          plt.figure()
          plt.title("Ground Truth and Regions 6/5/2008 cluster at DU=" + str(t) )
          plt.imshow(np.dstack((np.int_(im_orig), im_bin, im_bin))*255)
          plt.show()

#t_p_plot = np.where(np.array(all_true_positives_c) > 0, all_true_positives_c, np.nan)

fig, ax = plt.subplots(1,1)

#ax.plot( np.arange(len(all_true_positives_c)), all_true_positives_c, label="True Positives")
ax.plot( np.arange(len(all_false_positives_c)), all_false_positives_c, label="False Positives")
ax.plot( np.arange(len(all_false_negatives_c)), all_false_negatives_c, label="False Negatives")

ax.set_title('False Positive and False Negative - IASI UT 6/5/2008')# + imageLT.image_type + " - " + str(imageLT.day) +"/"+ str(imageLT.month) +"/"+ str(imageLT.year))
ax.set_xlabel("DU units")
ax.set_ylabel("FP and FN %")
ax.set_ylim([0,100])
ax.set_xlim([10,45])
ax.legend()

f , axx = plt.subplots(1,1)
axx.plot(all_false_positives_c, all_false_negatives_c)
axx.set_xlim([0,100])
#axx.set_ylim([0,100])

#centroids, grays_values,
my_x_norm =list()

for i,centroid in enumerate(centroids[:]):
  x = centroid[0] 
  y = centroid[1]
  z = grays_values[i]
  my_x_norm.append(np.array([x,y,z]))

my_X = np.asarray(my_x_norm)

fig = plt.figure(figsize=(11,8))
ax = fig.add_subplot(111, projection='3d')

for ii in range(len(my_X[:,2])):
  if my_X[ii,2] > 22:
    ax.scatter(my_X[ii,0],my_X[ii,1],my_X[ii,2])

ax.set_zlim([0,45])
#ax.view_init(30, 30)
#plt.draw()
#plt.pause(.001)
fig.show()

for x in labels_cc[:1]:
  print(x)

#rescale=1.0
#centroids = list()
#areas_partition = list()
#boxes_partition = list()
#grays_values = list()
#ids_valid_regions = list()

for i,region in enumerate(measure.regionprops(label_image=labels_cc)):
  x_min = region.bbox[1]
  x_max = region.bbox[3]
  y_min = region.bbox[0]
  y_max = region.bbox[2]

  # TODO: CORREGIR EL PROBLEMA CON LAS CLUSTERS Y LAS REGIONES QUE SE PIERDEN
  #if (x_max - x_min) > min_width and (y_max - y_min) > min_height:
  #boxes_partition.append(np.array([x_min,y_min,x_max,y_max]))
  #cx, cy = map(lambda p: int(p*rescale), (region.centroid[0], region.centroid[1]))
  #centroids.append((cx, cy))
  #areas_partition.append(region.area)
  #grays_values.append(self.get_region_value(image_masked,np.array([x_min,y_min,x_max,y_max]),True)) # Gray values for the regions partitions
  #ids_valid_regions.append(i) # List to compare with CC. The idea is to rebuild the region as image, to do that we need the region id









directories = os.listdir( DIR_TRAIN )

container_tp_days = list()
container_fp_days = list()
container_fn_days = list()


for i in range(1,8):
  print(i)

  year_test = 2008
  month_test = 5
  day_test = i
  image_type_test = "LT"
  cluster_labels1 = cluster_labels + 1 # all_labels_lt[day_test - 1] + 1
  image_cluster_test = image_cluster.copy() # all_images_cluster_lt[day_test - 1]

  # This would print all the files and directories
  for file in directories:
    only_png_files = re.search(".jpg", file)
    if only_png_files is not None:
      only_same_day = re.search(str(year_test)+"%02d"%month_test+"%02d"%day_test, file)
      if only_same_day is not None:
        only_image_type = re.search(image_type_test, file)
        if only_image_type is not None:
          img = io.imread(DIR_TRAIN + file)
          #img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
          img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
          img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
          #img_gray = ma.masked_values(img_gray, 255.)
          img_gray = cv2.GaussianBlur(img_gray,(5,5),cv2.BORDER_DEFAULT)

          best_regions_c = list()
          worst_regions_c = list()

          all_true_positives_c = list()
          all_true_negatives_c = list()
          all_false_positives_c = list()
          all_false_negatives_c = list()
          all_accuracy_c = list()
          f_p = list()
          f_n = list()

          
          im_acum = np.zeros(image_cluster.shape, np.uint8)

          for i in range(1,max(cluster_labels1) + 1):
            im_bin = img_gray.copy()


            seuil = 1

            im_orig1 = np.zeros(image_cluster.shape, np.uint8)
            im_orig1 = np.where(image_cluster == i,1, im_orig1)
            
            contours_orig, _ = cv2.findContours(im_orig1, 1, 2)

            for i,cnt in enumerate(contours_orig):
              box = cv2.boundingRect(cnt)
              x,y,w,h = box
              
              if ( w*h ) > 1000:
                g = get_region_value2(image,box)
                im_acum = np.where(image_cluster == i, g, im_acum)
                im_orig1 = np.where(image_cluster == i,g, im_orig1)

            im_acum = np.where(im_acum < seuil, 0, im_acum)

            im_bin = cv2.normalize(im_bin, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)
            im_orig = cv2.normalize(im_acum, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)

            ## CONTOURS IM_BIN
            contours_bin, _ = cv2.findContours(im_bin, 1, 2)

            cx_bin_centers = list()
            cy_bin_centers = list()

            for cnt in contours_bin:
              x,y,w,h = cv2.boundingRect(cnt)
              cx = ( x + (x + w) ) / 2
              cy = ( y + (y + h) ) / 2 
              
              cx_bin_centers.append(cx)
              cy_bin_centers.append(cy)

            cx_bin_mean = np.mean(cx_bin_centers)
            cy_bin_mean = np.mean(cy_bin_centers)
                      
  
            #cx_mean_orig = np.mean(c_orig_centers[:,0])
            #cy_mean_orig = np.mean(c_orig_centers)
            #print(cx_mean_orig,cy_mean_orig)
            
            
            #cnt_orig = contours_orig[0]
            #M_orig = cv2.moments(cnt_orig)
            #print("area: ",M_orig['m00'])

            ## Calculate centroid
            #cx_orig = int(M_orig['m10']/M_orig['m00'])
            #cy_orig = int(M_orig['m01']/M_orig['m00'])
            
            c_m_temp = confusion_matrix(im_bin.flatten(), im_orig.flatten())
            true_positives = c_m_temp[1][1]
            false_positives = c_m_temp[0][1]
            false_negatives = c_m_temp[1][0]
            true_negatives = c_m_temp[0][0]

            f_p.append(false_positives)
            f_n.append(false_negatives)

            accuracy = accuracy_score(im_bin.flatten(),im_orig.flatten()) * 100
            total_pixels_blancs_ref = len(im_bin[im_bin == 1])
            total_pixels_blancs_test = len(im_orig[im_orig == 1])

            #im_test_ones = np.ones(im_bin.shape, np.uint8)
            #im_test_ones = np.where(im_bin == 1,0,im_test_ones)
            #im_test_ones = np.where(im_orig == 1,0,im_test_ones)
            #total_pixels_noirs = len(im_test_ones[im_test_ones == 1])

            #print("pixels: true_positives", true_positives)
            #print("pixels: false_positives",false_positives)
            #print("pixels: false_negatives",false_negatives)
            #print("pixels: true_negatives",true_negatives)
            #print("total_pixels_blancs_ref", total_pixels_blancs_ref)
            #print("total_pixels_blancs_test", total_pixels_blancs_test)
            
            #print("perc: true_positives", int(true_positives * 100 / total_pixels_blancs_test), "%")
            #print("perc: false_positives", int(false_positives * 100 / total_pixels_blancs_test), "%")
            #print("perc: false_negatives", int(false_negatives * 100 / total_pixels_blancs_ref), "%")
            ##print("perc: true_negatives", int(true_negatives * 100 / total_pixels_noirs), "%")

            perc_TP = true_positives * 100 / total_pixels_blancs_test

            if day_test == 6:#perc_TP > 5 and day_test == 6:
              all_true_positives_c.append(true_positives * 100 / total_pixels_blancs_test)
              all_false_positives_c.append(false_positives * 100 / total_pixels_blancs_test)
              all_false_negatives_c.append(false_negatives * 100 / total_pixels_blancs_ref)
              all_accuracy_c.append(accuracy)
              #mid_point_x = (cx_orig_mean + cx_bin_mean) / 2
              #mid_point_y = (cy_orig_mean + cy_bin_mean) / 2

              ## visualize the differences between the original image and the solution
              plt.figure()
              plt.title("Ground Truth and Regions " + str(day_test) + " cluster - " + str(i) )
              #plt.plot([cx_orig_mean,cx_bin_mean], [cy_orig_mean,cy_bin_mean], "--",c="white")
              #plt.scatter([mid_point_x],[mid_point_y], c="yellow")
              plt.imshow(np.dstack((np.int_(im_orig), im_bin, im_bin))*255)
              plt.show()
  #container_tp_days.append(all_true_positives_c)
  #container_fp_days.append(all_false_positives_c)
  #container_fn_days.append(all_false_negatives_c)

## To plot all the TP in all available days

# cami means list of all tp without array separations
# dani len of array each day

cami = list()
dani = list()

for tp in container_tp_days:
  dani.append(len(tp))
  for val in tp:
    cami.append(val)

print(cami)
print(dani)
print(np.mean(dani))

# testing ut
juli = np.full((100,), 5)
juli2 = np.full((100,) , 5 + 5)
juli3 = np.full((100,) , 5 + 5 + 5)
juli4 = np.full((100,) , 5 + 5 + 5 + 4)
juli5 = np.full((100,) , 5 + 5 + 5 + 4 + 6)
juli6 = np.full((100,) , 5 + 5 + 5 + 4 + 6 + 5)

#testing LT
juli = np.full((100,), 8)
juli2 = np.full((100,) , 8 + 8)
juli3 = np.full((100,) , 8 + 8 + 7)
juli4 = np.full((100,) , 8 + 8 + 7 + 4)
juli5 = np.full((100,) , 8 + 8 + 7 + 4 + 9)
juli6 = np.full((100,) , 8 + 8 + 7 + 4 + 9 + 8)

plt.plot(juli6, np.arange(len(juli6)), "--", label="06/05")
plt.plot(juli5, np.arange(len(juli5)), "--", label="05/05")
plt.plot(juli4, np.arange(len(juli4)), "--", label="04/05")
plt.plot(juli3, np.arange(len(juli3)), "--", label="03/05")
plt.plot(juli2, np.arange(len(juli2)), "--", label="02/05")
plt.plot(juli, np.arange(len(juli)), "--", label="01/05")
plt.plot(np.arange(len(cami)), cami, label="TP")
plt.title("True positives UT - IASI 1-6/5/2008")
plt.legend()

sensitivity_c = list()
for i,tp in enumerate(all_true_positives_c):
  sensitivity_c.append(tp / (tp + all_false_negatives_c[i]) * 100) 


print(all_true_positives_c)

#t_p_plot = np.where(np.array(all_true_positives_c) > 0, all_true_positives_c, np.nan)

fig, ax = plt.subplots(1,1)
#ax.plot( np.arange(len(t_p_plot)), t_p_plot + 10, label="TP")
ax.plot( np.arange(len(all_true_positives_c)), all_true_positives_c, label="True Positives")
ax.plot( np.arange(len(all_false_positives_c)), all_false_positives_c, label="False Positives")
ax.plot( np.arange(len(all_false_negatives_c)), all_false_negatives_c, label="False Negatives")
ax.plot( np.arange(len(all_accuracy_c)), all_accuracy_c, "--", label="Accuracy")
#ax.plot( np.arange(len(sensitivity_c)), sensitivity_c, "--", label="Sensitivity")

ax.set_title('Confusion matrix variation - IASI LT 6/5/2008')# + imageLT.image_type + " - " + str(imageLT.day) +"/"+ str(imageLT.month) +"/"+ str(imageLT.year))
ax.set_xlabel("Cluster index")
ax.set_ylabel("Confusion matrix values %")
ax.set_ylim([0,100])
ax.legend()

xx_r = [0, 110]
yy_r = [0, 110]
fig, ax = plt.subplots(1,1)

plt_f_p = np.unique(all_false_positives_c) # como hay valores repetidos, solo ploteare la linea de los que no son repetidos
plt_f_n = np.unique(all_false_negatives_c)

#ax.plot(plt_f_p, plt_f_n)
ax.plot(all_false_positives_c, all_false_negatives_c)
ax.scatter([all_false_positives_c], [all_false_negatives_c])
ax.set_xlabel("% False Negatives")
ax.set_ylabel("% False Positives")
ax.set_xlim(*xx_r)
ax.set_ylim(*yy_r)
#ax.plot( all_false_positives_c, all_false_negatives_c, label="False Negatives")
#ax.legend()
fig.show()















def setIterationForDay(day=1,typei="LT"):
  imageLT = SplitImageLevels()
  month=5

  imageLT.set_year(2008)
  imageLT.set_month(month)
  imageLT.set_day(day)
  imageLT.set_image_type(typei)
  imageLT.set_image_name("levels")
  imageLT.set_weight_gray_values(1)
  imageLT.set_cluster_value(30)
  imageLT.set_pixel_size(0.25,.125)
  imageLT.get_image_by_leves()
  bgr , gray = imageLT.load_image_from_files(imageLT.get_image_name())
  image, foreground, background = imageLT.filter_image(gray)
  kernel = np.ones((3,3),np.uint8)
  foreground = cv2.dilate(foreground,kernel,iterations = 3)
  image1 = cv2.bitwise_and(image,image, mask=foreground)
  image2 = cv2.bitwise_and(image,image, mask=background)
  myimage = cv2.cvtColor(image1, cv2.COLOR_GRAY2RGB)
  myimage = cv2.bitwise_and(myimage,myimage, mask=foreground)
  t_i = ma.masked_values(image1, 0.)
  mser = cv2.MSER_create( 1, # delta 
                        100, # min_area
                        34400, #max_area 
                        4., # max_variation 
                        .01, # min_diversity 
                        10000, # max_evolution 
                        1.04, # area_threshold 
                        0.003, # min_margin
                        5) # edge_blur_size

  # (1, 100, 20000, .25, 1., 1000, 1.001, 0.003, 5)
  regions, bboxes = mser.detectRegions(myimage)
  regions = sorted(regions, key=cv2.contourArea, reverse=True)
  regx, regy, polys, lines, values = imageLT.set_mser_regions(t_i, background, regions[:])
  
  export_original_d(day,typei)
  export_regions(day,typei)

def export_original_d(day=1,typei="LT"):
  month=5
  fig2, (ax2) = plt.subplots(1, 1, figsize = (11,8))
  ax2.pcolormesh(imageLT.v_x, imageLT.v_y, imageLT.colgrid1, shading='nearest',cmap='jet', vmin=imageLT.vmin, vmax=imageLT.vmax)
  ax2.axis('off')
  image_name = typei + '-color-' + str(2008) + '%02d'%month+'%02d'%day+'.png'
  fig2.savefig(DIR_TEST + "06-06/"+ image_name, bbox_inches='tight', pad_inches=0)
  plt.close(fig2)

def export_regions(day=1,typei="LT"):
  month=5
  x_range = [0, image.shape[1]]
  y_range = [0, image.shape[0]]

  fig, ax = plt.subplots(1,1, figsize=(11,8), facecolor=(0, 0, 0))

  if imageLT.image_type == 'LT':
    max_color_value = 35
  else:
    max_color_value = 45

  colors = sns.color_palette("YlOrBr_r", max_color_value + 1)
  cmap = matplotlib.colors.ListedColormap(colors)
  norm = matplotlib.colors.BoundaryNorm(np.arange(max_color_value + 1) - 0.5, cmap.N)

  for i,val in enumerate(values):
    ax.scatter(regx[i], regy[i], marker='.', color=cmap(norm(int(val))) )
    ax.set_xlim(*x_range)
    ax.set_ylim(*y_range)
    ax.invert_yaxis()
    ax.axis('off')

  matplotlib.cm.ScalarMappable(cmap=cmap, norm=norm)
  image_name = typei + '-reg-' + str(2008) + '%02d'%month+'%02d'%day+'.png'
  fig.savefig(DIR_TEST + "06-06/" + image_name, bbox_inches='tight', pad_inches=0,transparent=True)
  plt.close(fig)









